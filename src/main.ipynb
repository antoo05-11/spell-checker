{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import requests\n",
    "from tqdm import tqdm\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# URL to the directory containing the files to be downloaded\n",
    "language = \"en-es\"\n",
    "url = f\"https://data.statmt.org/opus-100-corpus/v1.0/supervised/{language}/\"\n",
    "save_directory = f\"../data/{language}\"\n",
    "\n",
    "# Create the save directory if it doesn't exist\n",
    "os.makedirs(save_directory, exist_ok=True)\n",
    "\n",
    "# Send a GET request to the URL\n",
    "response = requests.get(url)\n",
    "\n",
    "# Parse the HTML response\n",
    "soup = BeautifulSoup(response.content, 'html.parser')\n",
    "\n",
    "# Find all the anchor tags in the HTML\n",
    "links = soup.find_all('a')\n",
    "\n",
    "# Extract the href attribute from each anchor tag\n",
    "file_links = [link['href'] for link in links if '.' in link['href']]\n",
    "\n",
    "# Download each file\n",
    "for file_link in tqdm(file_links):\n",
    "    file_url = url + file_link\n",
    "    save_path = os.path.join(save_directory, file_link)\n",
    "    \n",
    "    print(f\"Downloading {file_url}\")\n",
    "    \n",
    "    # Send a GET request for the file\n",
    "    file_response = requests.get(file_url)\n",
    "    if file_response.status_code == 404:\n",
    "        print(f\"Could not download {file_url}\")\n",
    "        continue\n",
    "    \n",
    "    # Save the file to the specified directory\n",
    "    with open(save_path, 'wb') as file:\n",
    "        file.write(file_response.content)\n",
    "    \n",
    "    print(f\"Saved {file_link}\")\n",
    "\n",
    "print(\"All files have been downloaded.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "en_training_data_path = \"../data/en-es/opus.en-es-train.en\"\n",
    "en_validation_data_path = \"../data/en-es/opus.en-es-dev.en\"\n",
    "es_training_data_path = \"../data/en-es/opus.en-es-train.es\"\n",
    "es_validation_data_path = \"../data/en-es/opus.en-es-dev.es\"\n",
    "\n",
    "def read_files(path):\n",
    "    with open(path, \"r\", encoding=\"utf-8\") as f:\n",
    "        en_train_dataset = f.read().split(\"\\n\")[:-1]\n",
    "    return en_train_dataset\n",
    "\n",
    "en_training_data = read_files(en_training_data_path)\n",
    "en_validation_data = read_files(en_validation_data_path)\n",
    "es_training_data = read_files(es_training_data_path)\n",
    "es_validation_data = read_files(es_validation_data_path)\n",
    "\n",
    "max_length = 500\n",
    "train_dataset = [[es_sentence, en_sentence] for es_sentence, en_sentence in zip(es_training_data, en_training_data) if len(es_sentence) <= max_length and len(en_sentence) <= max_length]\n",
    "val_dataset = [[es_sentence, en_sentence] for es_sentence, en_sentence in zip(es_validation_data, en_validation_data) if len(es_sentence) <= max_length and len(en_sentence) <= max_length]\n",
    "es_training_data, en_training_data = zip(*train_dataset)\n",
    "es_validation_data, en_validation_data = zip(*val_dataset)\n",
    "\n",
    "print(len(es_training_data))\n",
    "print(len(es_validation_data))\n",
    "print(es_training_data[:3])\n",
    "print(en_training_data[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "en_training_data = en_training_data[:100]\n",
    "es_training_data = es_training_data[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from custom_tokenizer import CustomTokenizer\n",
    "\n",
    "# prepare Spanish tokenizer, this is the input language\n",
    "tokenizer = CustomTokenizer(char_level=True)\n",
    "tokenizer.fit_on_texts(es_training_data)\n",
    "tokenizer.save(\"tokenizer.json\")\n",
    "\n",
    "# prepare English tokenizer, this is the output language\n",
    "detokenizer = CustomTokenizer(char_level=True)\n",
    "detokenizer.fit_on_texts(en_training_data)\n",
    "detokenizer.save(\"detokenizer.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[33, 51, 48, 55, 55, 58, 3, 66, 58, 61, 55, 47, 15, 3, 51, 58, 66, 3, 44, 61, 48, 3, 68, 58, 64, 36, 32]\n",
      "['<start>hello world, how are you?<eos>']\n",
      "['hello world, how are you?']\n"
     ]
    }
   ],
   "source": [
    "tokenized_sentence = detokenizer.texts_to_sequences([\"Hello world, how are you?\"])[0]\n",
    "print(tokenized_sentence)\n",
    "\n",
    "detokenized_sentence = detokenizer.detokenize([tokenized_sentence], remove_start_end=False)\n",
    "print(detokenized_sentence)\n",
    "\n",
    "detokenized_sentence = detokenizer.detokenize([tokenized_sentence])\n",
    "print(detokenized_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mltu.tensorflow.dataProvider import DataProvider\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def preprocess_inputs(data_batch, label_batch):\n",
    "    encoder_input = np.zeros((len(data_batch), tokenizer.max_length)).astype(np.int64)\n",
    "    decoder_input = np.zeros((len(label_batch), detokenizer.max_length)).astype(\n",
    "        np.int64\n",
    "    )\n",
    "    decoder_output = np.zeros((len(label_batch), detokenizer.max_length)).astype(\n",
    "        np.int64\n",
    "    )\n",
    "\n",
    "    data_batch_tokens = tokenizer.texts_to_sequences(data_batch)\n",
    "    label_batch_tokens = detokenizer.texts_to_sequences(label_batch)\n",
    "\n",
    "    for index, (data, label) in enumerate(zip(data_batch_tokens, label_batch_tokens)):\n",
    "        encoder_input[index][: len(data)] = data\n",
    "        decoder_input[index][: len(label) - 1] = label[:-1]  # Drop the [END] tokens\n",
    "        decoder_output[index][: len(label) - 1] = label[1:]  # Drop the [START] tokens\n",
    "\n",
    "    return (encoder_input, decoder_input), decoder_output\n",
    "\n",
    "\n",
    "train_dataProvider = DataProvider(\n",
    "    train_dataset,\n",
    "    batch_size=4,\n",
    "    batch_postprocessors=[preprocess_inputs],\n",
    "    use_cache=True,\n",
    ")\n",
    "\n",
    "val_dataProvider = DataProvider(\n",
    "    val_dataset, batch_size=4, batch_postprocessors=[preprocess_inputs], use_cache=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for data_batch in train_dataProvider:\n",
    "    (encoder_inputs, decoder_inputs), decoder_outputs = data_batch\n",
    "\n",
    "    encoder_inputs_str = tokenizer.detokenize(encoder_inputs)\n",
    "    decoder_inputs_str = detokenizer.detokenize(decoder_inputs, remove_start_end=False)\n",
    "    decoder_outputs_str = detokenizer.detokenize(\n",
    "        decoder_outputs, remove_start_end=False\n",
    "    )\n",
    "    print(encoder_inputs_str)\n",
    "    print(decoder_inputs_str)\n",
    "    print(decoder_outputs_str)\n",
    "\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fitting tokenizer: 100%|██████████| 200/200 [00:00<00:00, 210928.04it/s]\n",
      "Fitting tokenizer: 100%|██████████| 200/200 [00:00<00:00, 356052.97it/s]\n",
      "/home/thanhan/.local/lib/python3.10/site-packages/keras/src/layers/layer.py:845: UserWarning: Layer 'global_self_attention_16' (of type GlobalSelfAttention) was passed an input with a mask attached to it. However, this layer does not support masking and will therefore destroy the mask information. Downstream layers will not see the mask.\n",
      "  warnings.warn(\n",
      "/home/thanhan/.local/lib/python3.10/site-packages/keras/src/layers/layer.py:845: UserWarning: Layer 'encoder_layer_16' (of type EncoderLayer) was passed an input with a mask attached to it. However, this layer does not support masking and will therefore destroy the mask information. Downstream layers will not see the mask.\n",
      "  warnings.warn(\n",
      "/home/thanhan/.local/lib/python3.10/site-packages/keras/src/layers/layer.py:845: UserWarning: Layer 'causal_self_attention_16' (of type CausalSelfAttention) was passed an input with a mask attached to it. However, this layer does not support masking and will therefore destroy the mask information. Downstream layers will not see the mask.\n",
      "  warnings.warn(\n",
      "/home/thanhan/.local/lib/python3.10/site-packages/keras/src/layers/layer.py:845: UserWarning: Layer 'decoder_layer_16' (of type DecoderLayer) was passed an input with a mask attached to it. However, this layer does not support masking and will therefore destroy the mask information. Downstream layers will not see the mask.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_49\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional_49\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)        </span>┃<span style=\"font-weight: bold\"> Output Shape      </span>┃<span style=\"font-weight: bold\">    Param # </span>┃<span style=\"font-weight: bold\"> Connected to      </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_40      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">371</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ input_layer_41      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">347</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ encoder_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Encoder</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">371</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)  │  <span style=\"color: #00af00; text-decoration-color: #00af00\">2,649,216</span> │ input_layer_40[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ decoder_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Decoder</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">347</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)  │  <span style=\"color: #00af00; text-decoration-color: #00af00\">4,759,296</span> │ input_layer_41[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
       "│                     │                   │            │ encoder_4[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_84 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">347</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">74</span>)   │      <span style=\"color: #00af00; text-decoration-color: #00af00\">9,546</span> │ decoder_4[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_40      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m371\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ input_layer_41      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m347\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ encoder_4 (\u001b[38;5;33mEncoder\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m371\u001b[0m, \u001b[38;5;34m128\u001b[0m)  │  \u001b[38;5;34m2,649,216\u001b[0m │ input_layer_40[\u001b[38;5;34m0\u001b[0m… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ decoder_4 (\u001b[38;5;33mDecoder\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m347\u001b[0m, \u001b[38;5;34m128\u001b[0m)  │  \u001b[38;5;34m4,759,296\u001b[0m │ input_layer_41[\u001b[38;5;34m0\u001b[0m… │\n",
       "│                     │                   │            │ encoder_4[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_84 (\u001b[38;5;33mDense\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m347\u001b[0m, \u001b[38;5;34m74\u001b[0m)   │      \u001b[38;5;34m9,546\u001b[0m │ decoder_4[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">7,418,058</span> (28.30 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m7,418,058\u001b[0m (28.30 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">7,418,058</span> (28.30 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m7,418,058\u001b[0m (28.30 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from model import Transformer\n",
    "from configs import ModelConfigs\n",
    "from custom_tokenizer import CustomTokenizer\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "try:\n",
    "    [\n",
    "        tf.config.experimental.set_memory_growth(gpu, True)\n",
    "        for gpu in tf.config.experimental.list_physical_devices(\"GPU\")\n",
    "    ]\n",
    "except:\n",
    "    pass\n",
    "\n",
    "from keras.callbacks import (\n",
    "    EarlyStopping,\n",
    "    ModelCheckpoint,\n",
    "    ReduceLROnPlateau,\n",
    "    TensorBoard,\n",
    ")\n",
    "from mltu.tensorflow.callbacks import Model2onnx, WarmupCosineDecay\n",
    "\n",
    "from mltu.tensorflow.dataProvider import DataProvider\n",
    "from mltu.tokenizers import CustomTokenizer\n",
    "\n",
    "from mltu.tensorflow.transformer.utils import MaskedAccuracy, MaskedLoss\n",
    "from mltu.tensorflow.transformer.callbacks import EncDecSplitCallback\n",
    "\n",
    "configs = ModelConfigs()\n",
    "\n",
    "# Path to dataset\n",
    "en_training_data_path = \"../data/en-es/opus.en-es-train.en\"\n",
    "en_validation_data_path = \"../data/en-es/opus.en-es-dev.en\"\n",
    "es_training_data_path = \"../data/en-es/opus.en-es-train.es\"\n",
    "es_validation_data_path = \"../data/en-es/opus.en-es-dev.es\"\n",
    "\n",
    "\n",
    "def read_files(path):\n",
    "    with open(path, \"r\", encoding=\"utf-8\") as f:\n",
    "        en_train_dataset = f.read().split(\"\\n\")[:-1]\n",
    "    return en_train_dataset\n",
    "\n",
    "\n",
    "en_training_data = read_files(en_training_data_path)[:200]\n",
    "en_validation_data = read_files(en_validation_data_path)[:200]\n",
    "es_training_data = read_files(es_training_data_path)[:200]\n",
    "es_validation_data = read_files(es_validation_data_path)[:200]\n",
    "\n",
    "# Consider only sentences with length <= 500\n",
    "max_length = 500\n",
    "train_dataset = [\n",
    "    [es_sentence, en_sentence]\n",
    "    for es_sentence, en_sentence in zip(es_training_data, en_training_data)\n",
    "    if len(es_sentence) <= max_length and len(en_sentence) <= max_length\n",
    "]\n",
    "val_dataset = [\n",
    "    [es_sentence, en_sentence]\n",
    "    for es_sentence, en_sentence in zip(es_validation_data, en_validation_data)\n",
    "    if len(es_sentence) <= max_length and len(en_sentence) <= max_length\n",
    "]\n",
    "es_training_data, en_training_data = zip(*train_dataset)\n",
    "es_validation_data, en_validation_data = zip(*val_dataset)\n",
    "\n",
    "# prepare spanish tokenizer, this is the input language\n",
    "tokenizer = CustomTokenizer(char_level=True)\n",
    "tokenizer.fit_on_texts(es_training_data)\n",
    "tokenizer.save(configs.model_path + \"/tokenizer.json\")\n",
    "\n",
    "# prepare english tokenizer, this is the output language\n",
    "detokenizer = CustomTokenizer(char_level=True)\n",
    "detokenizer.fit_on_texts(en_training_data)\n",
    "detokenizer.save(configs.model_path + \"/detokenizer.json\")\n",
    "\n",
    "\n",
    "def preprocess_inputs(data_batch, label_batch):\n",
    "    encoder_input = np.zeros((len(data_batch), tokenizer.max_length)).astype(np.int64)\n",
    "    decoder_input = np.zeros((len(label_batch), detokenizer.max_length)).astype(\n",
    "        np.int64\n",
    "    )\n",
    "    decoder_output = np.zeros((len(label_batch), detokenizer.max_length)).astype(\n",
    "        np.int64\n",
    "    )\n",
    "\n",
    "    \n",
    "\n",
    "    data_batch_tokens = tokenizer.texts_to_sequences(data_batch)\n",
    "    label_batch_tokens = detokenizer.texts_to_sequences(label_batch)\n",
    "\n",
    "    max_label_length = max(len(label) for label in label_batch_tokens)\n",
    "\n",
    "    decoder_input = np.zeros((len(label_batch), max_label_length - 1)).astype(np.int64)\n",
    "    decoder_output = np.zeros((len(label_batch), max_label_length - 1)).astype(np.int64)\n",
    "\n",
    "    for index, (data, label) in enumerate(zip(data_batch_tokens, label_batch_tokens)):\n",
    "        encoder_input[index][:len(data)] = data\n",
    "        decoder_input[index][:len(label) - 1] = label[:-1]  # Drop the [END] tokens\n",
    "        decoder_output[index][:len(label) - 1] = label[1:]  # Drop the [START] tokens\n",
    "\n",
    "    return (encoder_input, decoder_input), decoder_output\n",
    "\n",
    "\n",
    "# Create Training Data Provider\n",
    "train_dataProvider = DataProvider(\n",
    "    train_dataset,\n",
    "    batch_size=configs.batch_size,\n",
    "    batch_postprocessors=[preprocess_inputs],\n",
    "    use_cache=True,\n",
    ")\n",
    "\n",
    "# Create Validation Data Provider\n",
    "val_dataProvider = DataProvider(\n",
    "    val_dataset,\n",
    "    batch_size=configs.batch_size,\n",
    "    batch_postprocessors=[preprocess_inputs],\n",
    "    use_cache=True,\n",
    ")\n",
    "\n",
    "# Create TensorFlow Transformer Model\n",
    "transformer = Transformer(\n",
    "    num_layers=configs.num_layers,\n",
    "    d_model=configs.d_model,\n",
    "    num_heads=configs.num_heads,\n",
    "    dff=configs.dff,\n",
    "    input_vocab_size=len(tokenizer) + 1,\n",
    "    target_vocab_size=len(detokenizer) + 1,\n",
    "    dropout_rate=configs.dropout_rate,\n",
    "    encoder_input_size=tokenizer.max_length,\n",
    "    decoder_input_size=detokenizer.max_length,\n",
    ")\n",
    "\n",
    "transformer.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.keras.optimizers.Adam(learning_rate=configs.init_lr, beta_1=0.9, beta_2=0.98, epsilon=1e-9)\n",
    "\n",
    "# Compile the model\n",
    "transformer.compile(\n",
    "    loss=MaskedLoss(),\n",
    "    optimizer=optimizer,\n",
    "    metrics=[MaskedAccuracy()],\n",
    "    run_eagerly=False\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.optimizers.schedules import LearningRateSchedule\n",
    "\n",
    "class WarmupCosineDecay(LearningRateSchedule):\n",
    "\n",
    "    def __init__(self,\n",
    "                 initial_learning_rate,\n",
    "                 decay_steps,\n",
    "                 alpha,\n",
    "                 warmup_epochs):\n",
    "        super().__init__()\n",
    "\n",
    "        self.initial_learning_rate = initial_learning_rate\n",
    "        self.decay_steps = decay_steps\n",
    "        self.alpha = alpha\n",
    "        self.warmup_epochs = warmup_epochs\n",
    "\n",
    "    def __call__(self, step):\n",
    "        lr = self.initial_learning_rate\n",
    "        if step < self.warmup_epochs:\n",
    "            lr = lr * step / self.warmup_epochs\n",
    "        else:\n",
    "            lr = lr * 0.5 * (1 + math.cos(math.pi * (step - self.warmup_epochs) / self.decay_steps))\n",
    "        return lr * self.alpha\n",
    "\n",
    "warmupCosineDecay = WarmupCosineDecay(\n",
    "    initial_learning_rate=configs.init_lr,\n",
    "    decay_steps=configs.decay_epochs,\n",
    "    alpha=configs.final_lr / configs.init_lr,\n",
    "    warmup_epochs=configs.warmup_epochs,\n",
    ")\n",
    "\n",
    "earlystopper = EarlyStopping(monitor=\"val_masked_accuracy\", patience=5, verbose=1, mode=\"max\")\n",
    "checkpoint = ModelCheckpoint(f\"{configs.model_path}/model.keras\", monitor=\"val_masked_accuracy\", verbose=1, save_best_only=True, mode=\"max\", save_weights_only=False)\n",
    "tb_callback = TensorBoard(f\"{configs.model_path}/logs\")\n",
    "reduceLROnPlat = ReduceLROnPlateau(monitor=\"val_masked_accuracy\", factor=0.9, min_delta=1e-10, patience=2, verbose=1, mode=\"max\")\n",
    "model2onnx = Model2onnx(f\"{configs.model_path}/model.keras\", metadata={\"tokenizer\": tokenizer.dict(), \"detokenizer\": detokenizer.dict()}, save_on_epoch_end=False)\n",
    "encDecSplitCallback = EncDecSplitCallback(configs.model_path, encoder_metadata={\"tokenizer\": tokenizer.dict()}, decoder_metadata={\"detokenizer\": detokenizer.dict()})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - loss: 5.0007 - masked_accuracy: 0.0124"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-22 23:00:40.042433: W tensorflow/core/framework/op_kernel.cc:1827] INVALID_ARGUMENT: ValueError: could not broadcast input array from shape (395,) into shape (371,)\n",
      "Traceback (most recent call last):\n",
      "\n",
      "  File \"/home/thanhan/.local/lib/python3.10/site-packages/tensorflow/python/ops/script_ops.py\", line 270, in __call__\n",
      "    ret = func(*args)\n",
      "\n",
      "  File \"/home/thanhan/.local/lib/python3.10/site-packages/tensorflow/python/autograph/impl/api.py\", line 643, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "\n",
      "  File \"/home/thanhan/.local/lib/python3.10/site-packages/tensorflow/python/data/ops/from_generator_op.py\", line 198, in generator_py_func\n",
      "    values = next(generator_state.get_iterator(iterator_id))\n",
      "\n",
      "  File \"/home/thanhan/.local/lib/python3.10/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py\", line 250, in _get_iterator\n",
      "    for i, batch in enumerate(gen_fn()):\n",
      "\n",
      "  File \"/home/thanhan/.local/lib/python3.10/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py\", line 244, in generator_fn\n",
      "    yield self.py_dataset[i]\n",
      "\n",
      "  File \"/home/thanhan/.local/lib/python3.10/site-packages/mltu/dataProvider.py\", line 282, in __getitem__\n",
      "    batch_data, batch_annotations = batch_postprocessor(batch_data, batch_annotations)\n",
      "\n",
      "  File \"/tmp/ipykernel_96834/932217772.py\", line 97, in preprocess_inputs\n",
      "    encoder_input[index][:len(data)] = data\n",
      "\n",
      "ValueError: could not broadcast input array from shape (395,) into shape (371,)\n",
      "\n",
      "\n",
      "2024-03-22 23:00:40.961389: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: INVALID_ARGUMENT: ValueError: could not broadcast input array from shape (395,) into shape (371,)\n",
      "Traceback (most recent call last):\n",
      "\n",
      "  File \"/home/thanhan/.local/lib/python3.10/site-packages/tensorflow/python/ops/script_ops.py\", line 270, in __call__\n",
      "    ret = func(*args)\n",
      "\n",
      "  File \"/home/thanhan/.local/lib/python3.10/site-packages/tensorflow/python/autograph/impl/api.py\", line 643, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "\n",
      "  File \"/home/thanhan/.local/lib/python3.10/site-packages/tensorflow/python/data/ops/from_generator_op.py\", line 198, in generator_py_func\n",
      "    values = next(generator_state.get_iterator(iterator_id))\n",
      "\n",
      "  File \"/home/thanhan/.local/lib/python3.10/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py\", line 250, in _get_iterator\n",
      "    for i, batch in enumerate(gen_fn()):\n",
      "\n",
      "  File \"/home/thanhan/.local/lib/python3.10/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py\", line 244, in generator_fn\n",
      "    yield self.py_dataset[i]\n",
      "\n",
      "  File \"/home/thanhan/.local/lib/python3.10/site-packages/mltu/dataProvider.py\", line 282, in __getitem__\n",
      "    batch_data, batch_annotations = batch_postprocessor(batch_data, batch_annotations)\n",
      "\n",
      "  File \"/tmp/ipykernel_96834/932217772.py\", line 97, in preprocess_inputs\n",
      "    encoder_input[index][:len(data)] = data\n",
      "\n",
      "ValueError: could not broadcast input array from shape (395,) into shape (371,)\n",
      "\n",
      "\n",
      "\t [[{{node PyFunc}}]]\n",
      "\t [[IteratorGetNext]]\n"
     ]
    },
    {
     "ename": "InvalidArgumentError",
     "evalue": "Graph execution error:\n\nDetected at node PyFunc defined at (most recent call last):\n<stack traces unavailable>\nValueError: could not broadcast input array from shape (395,) into shape (371,)\nTraceback (most recent call last):\n\n  File \"/home/thanhan/.local/lib/python3.10/site-packages/tensorflow/python/ops/script_ops.py\", line 270, in __call__\n    ret = func(*args)\n\n  File \"/home/thanhan/.local/lib/python3.10/site-packages/tensorflow/python/autograph/impl/api.py\", line 643, in wrapper\n    return func(*args, **kwargs)\n\n  File \"/home/thanhan/.local/lib/python3.10/site-packages/tensorflow/python/data/ops/from_generator_op.py\", line 198, in generator_py_func\n    values = next(generator_state.get_iterator(iterator_id))\n\n  File \"/home/thanhan/.local/lib/python3.10/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py\", line 250, in _get_iterator\n    for i, batch in enumerate(gen_fn()):\n\n  File \"/home/thanhan/.local/lib/python3.10/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py\", line 244, in generator_fn\n    yield self.py_dataset[i]\n\n  File \"/home/thanhan/.local/lib/python3.10/site-packages/mltu/dataProvider.py\", line 282, in __getitem__\n    batch_data, batch_annotations = batch_postprocessor(batch_data, batch_annotations)\n\n  File \"/tmp/ipykernel_96834/932217772.py\", line 97, in preprocess_inputs\n    encoder_input[index][:len(data)] = data\n\nValueError: could not broadcast input array from shape (395,) into shape (371,)\n\n\n\t [[{{node PyFunc}}]]\n\t [[IteratorGetNext]] [Op:__inference_one_step_on_iterator_224962]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[42], line 14\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39moptimizer\u001b[38;5;241m.\u001b[39mlearning_rate \u001b[38;5;241m=\u001b[39m lr\n\u001b[1;32m     12\u001b[0m warmupCosineDecayCallback \u001b[38;5;241m=\u001b[39m WarmupCosineDecayCallback(warmupCosineDecay)\n\u001b[0;32m---> 14\u001b[0m \u001b[43mtransformer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     15\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_dataProvider\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     16\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mval_dataProvider\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     17\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfigs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_epochs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     18\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\n\u001b[1;32m     19\u001b[0m \u001b[43m        \u001b[49m\u001b[43mwarmupCosineDecayCallback\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     20\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcheckpoint\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     21\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtb_callback\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     22\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreduceLROnPlat\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     23\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodel2onnx\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     24\u001b[0m \u001b[43m        \u001b[49m\u001b[43mencDecSplitCallback\u001b[49m\n\u001b[1;32m     25\u001b[0m \u001b[43m    \u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m     26\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py:122\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m    120\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m    121\u001b[0m     \u001b[38;5;66;03m# `keras.config.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m--> 122\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    123\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    124\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/tensorflow/python/eager/execute.py:53\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     52\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 53\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m pywrap_tfe\u001b[38;5;241m.\u001b[39mTFE_Py_Execute(ctx\u001b[38;5;241m.\u001b[39m_handle, device_name, op_name,\n\u001b[1;32m     54\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[1;32m     55\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     56\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: Graph execution error:\n\nDetected at node PyFunc defined at (most recent call last):\n<stack traces unavailable>\nValueError: could not broadcast input array from shape (395,) into shape (371,)\nTraceback (most recent call last):\n\n  File \"/home/thanhan/.local/lib/python3.10/site-packages/tensorflow/python/ops/script_ops.py\", line 270, in __call__\n    ret = func(*args)\n\n  File \"/home/thanhan/.local/lib/python3.10/site-packages/tensorflow/python/autograph/impl/api.py\", line 643, in wrapper\n    return func(*args, **kwargs)\n\n  File \"/home/thanhan/.local/lib/python3.10/site-packages/tensorflow/python/data/ops/from_generator_op.py\", line 198, in generator_py_func\n    values = next(generator_state.get_iterator(iterator_id))\n\n  File \"/home/thanhan/.local/lib/python3.10/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py\", line 250, in _get_iterator\n    for i, batch in enumerate(gen_fn()):\n\n  File \"/home/thanhan/.local/lib/python3.10/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py\", line 244, in generator_fn\n    yield self.py_dataset[i]\n\n  File \"/home/thanhan/.local/lib/python3.10/site-packages/mltu/dataProvider.py\", line 282, in __getitem__\n    batch_data, batch_annotations = batch_postprocessor(batch_data, batch_annotations)\n\n  File \"/tmp/ipykernel_96834/932217772.py\", line 97, in preprocess_inputs\n    encoder_input[index][:len(data)] = data\n\nValueError: could not broadcast input array from shape (395,) into shape (371,)\n\n\n\t [[{{node PyFunc}}]]\n\t [[IteratorGetNext]] [Op:__inference_one_step_on_iterator_224962]"
     ]
    }
   ],
   "source": [
    "\n",
    "from tensorflow.keras.callbacks import Callback\n",
    "\n",
    "class WarmupCosineDecayCallback(Callback):\n",
    "    def __init__(self, warmupCosineDecay):\n",
    "        super().__init__()\n",
    "        self.warmupCosineDecay = warmupCosineDecay\n",
    "\n",
    "    def on_epoch_begin(self, epoch, logs=None):\n",
    "        lr = self.warmupCosineDecay(epoch)\n",
    "        self.model.optimizer.learning_rate = lr\n",
    "\n",
    "warmupCosineDecayCallback = WarmupCosineDecayCallback(warmupCosineDecay)\n",
    "\n",
    "transformer.fit(\n",
    "    train_dataProvider, \n",
    "    validation_data=val_dataProvider, \n",
    "    epochs=configs.train_epochs,\n",
    "    callbacks=[\n",
    "        warmupCosineDecayCallback,\n",
    "        checkpoint, \n",
    "        tb_callback, \n",
    "        reduceLROnPlat,\n",
    "        model2onnx,\n",
    "        encDecSplitCallback\n",
    "    ]\n",
    ")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
