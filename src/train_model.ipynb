{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import requests\n",
    "from tqdm import tqdm\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# URL to the directory containing the files to be downloaded\n",
    "language = \"en-es\"\n",
    "url = f\"https://data.statmt.org/opus-100-corpus/v1.0/supervised/{language}/\"\n",
    "save_directory = f\"../data/{language}\"\n",
    "\n",
    "# Create the save directory if it doesn't exist\n",
    "os.makedirs(save_directory, exist_ok=True)\n",
    "\n",
    "# Send a GET request to the URL\n",
    "response = requests.get(url)\n",
    "\n",
    "# Parse the HTML response\n",
    "soup = BeautifulSoup(response.content, 'html.parser')\n",
    "\n",
    "# Find all the anchor tags in the HTML\n",
    "links = soup.find_all('a')\n",
    "\n",
    "# Extract the href attribute from each anchor tag\n",
    "file_links = [link['href'] for link in links if '.' in link['href']]\n",
    "\n",
    "# Download each file\n",
    "for file_link in tqdm(file_links):\n",
    "    file_url = url + file_link\n",
    "    save_path = os.path.join(save_directory, file_link)\n",
    "    \n",
    "    print(f\"Downloading {file_url}\")\n",
    "    \n",
    "    # Send a GET request for the file\n",
    "    file_response = requests.get(file_url)\n",
    "    if file_response.status_code == 404:\n",
    "        print(f\"Could not download {file_url}\")\n",
    "        continue\n",
    "    \n",
    "    # Save the file to the specified directory\n",
    "    with open(save_path, 'wb') as file:\n",
    "        file.write(file_response.content)\n",
    "    \n",
    "    print(f\"Saved {file_link}\")\n",
    "\n",
    "print(\"All files have been downloaded.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-24 16:01:56.448522: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-03-24 16:01:56.829213: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-03-24 16:01:58.143077: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "from custom_tokenizer import CustomTokenizer\n",
    "from configs import ModelConfigs\n",
    "from mltu.tensorflow.dataProvider import DataProvider\n",
    "from transformer import Transformer\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_dir = os.path.join(os.getcwd(), \"../data\")\n",
    "\n",
    "\n",
    "def read_data(path):\n",
    "    sentences = []\n",
    "    with open(path, \"r\", encoding=\"utf-8\") as f:\n",
    "        sentences = f.read().split(\"\\n\")[:-1]\n",
    "    return sentences\n",
    "\n",
    "\n",
    "en_train_data = read_data(path=os.path.join(file_dir, \"en-es/opus.en-es-train.en\"))[:200]\n",
    "es_train_data = read_data(path=os.path.join(file_dir, \"en-es/opus.en-es-train.es\"))[:200]\n",
    "en_val_data = read_data(path=os.path.join(file_dir, \"en-es/opus.en-es-dev.en\"))[:200]\n",
    "es_val_data = read_data(path=os.path.join(file_dir, \"en-es/opus.en-es-dev.es\"))[:200]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "configs = ModelConfigs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_length = 20\n",
    "train_dataset = [\n",
    "    [es_sentence, en_sentence]\n",
    "    for es_sentence, en_sentence in zip(es_train_data, en_train_data)\n",
    "    if len(es_sentence) <= max_length and len(en_sentence) <= max_length\n",
    "]\n",
    "val_dataset = [\n",
    "    [es_sentence, en_sentence]\n",
    "    for es_sentence, en_sentence in zip(es_val_data, en_val_data)\n",
    "    if len(es_sentence) <= max_length and len(en_sentence) <= max_length\n",
    "]\n",
    "es_train_data, en_train_data = zip(*train_dataset)\n",
    "es_val_data, en_val_data = zip(*val_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fitting tokenizer: 100%|██████████| 122/122 [00:00<00:00, 236353.39it/s]\n",
      "Fitting tokenizer: 100%|██████████| 122/122 [00:00<00:00, 373234.93it/s]\n"
     ]
    }
   ],
   "source": [
    "tokenizer = CustomTokenizer(char_level=True)\n",
    "detokenizer = CustomTokenizer(char_level=True)\n",
    "\n",
    "tokenizer.fit_on_texts(es_train_data)\n",
    "tokenizer.save(\"model/tokenize/tokenizer.json\")\n",
    "\n",
    "detokenizer.fit_on_texts(en_train_data)\n",
    "detokenizer.save(\"model/tokenize/detokenizer.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_inputs(data_batch, label_batch):\n",
    "    encoder_input = np.zeros((len(data_batch), tokenizer.max_length)).astype(np.int64)\n",
    "    decoder_input = np.zeros((len(label_batch), detokenizer.max_length)).astype(np.int64)\n",
    "    decoder_output = np.zeros((len(label_batch), detokenizer.max_length)).astype(np.int64)\n",
    "\n",
    "    data_batch_tokens = tokenizer.texts_to_sequences(data_batch)\n",
    "    label_batch_tokens = detokenizer.texts_to_sequences(label_batch)\n",
    "\n",
    "    for index, (data, label) in enumerate(zip(data_batch_tokens, label_batch_tokens)):\n",
    "        encoder_input[index][:len(data)] = data\n",
    "        decoder_input[index][:len(label)-1] = label[:-1] # Drop the [END] tokens\n",
    "        decoder_output[index][:len(label)-1] = label[1:] # Drop the [START] tokens\n",
    "\n",
    "    return (encoder_input, decoder_input), decoder_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataProvider = DataProvider(\n",
    "    train_dataset,\n",
    "    batch_size=configs.batch_size,\n",
    "    batch_postprocessors=[preprocess_inputs],\n",
    "    use_cache=True,\n",
    ")\n",
    "\n",
    "val_dataProvider = DataProvider(\n",
    "    val_dataset,\n",
    "    batch_size=configs.batch_size,\n",
    "    batch_postprocessors=[preprocess_inputs],\n",
    "    use_cache=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/thanhan/.local/lib/python3.10/site-packages/keras/src/layers/layer.py:845: UserWarning: Layer 'query' (of type EinsumDense) was passed an input with a mask attached to it. However, this layer does not support masking and will therefore destroy the mask information. Downstream layers will not see the mask.\n",
      "  warnings.warn(\n",
      "/home/thanhan/.local/lib/python3.10/site-packages/keras/src/layers/layer.py:845: UserWarning: Layer 'key' (of type EinsumDense) was passed an input with a mask attached to it. However, this layer does not support masking and will therefore destroy the mask information. Downstream layers will not see the mask.\n",
      "  warnings.warn(\n",
      "/home/thanhan/.local/lib/python3.10/site-packages/keras/src/layers/layer.py:845: UserWarning: Layer 'value' (of type EinsumDense) was passed an input with a mask attached to it. However, this layer does not support masking and will therefore destroy the mask information. Downstream layers will not see the mask.\n",
      "  warnings.warn(\n",
      "/home/thanhan/.local/lib/python3.10/site-packages/keras/src/layers/layer.py:845: UserWarning: Layer 'global_self_attention' (of type GlobalSelfAttention) was passed an input with a mask attached to it. However, this layer does not support masking and will therefore destroy the mask information. Downstream layers will not see the mask.\n",
      "  warnings.warn(\n",
      "/home/thanhan/.local/lib/python3.10/site-packages/keras/src/layers/layer.py:845: UserWarning: Layer 'encoder_layer' (of type EncoderLayer) was passed an input with a mask attached to it. However, this layer does not support masking and will therefore destroy the mask information. Downstream layers will not see the mask.\n",
      "  warnings.warn(\n",
      "/home/thanhan/.local/lib/python3.10/site-packages/keras/src/layers/layer.py:845: UserWarning: Layer 'causal_self_attention' (of type CausalSelfAttention) was passed an input with a mask attached to it. However, this layer does not support masking and will therefore destroy the mask information. Downstream layers will not see the mask.\n",
      "  warnings.warn(\n",
      "/home/thanhan/.local/lib/python3.10/site-packages/keras/src/layers/layer.py:845: UserWarning: Layer 'decoder_layer' (of type DecoderLayer) was passed an input with a mask attached to it. However, this layer does not support masking and will therefore destroy the mask information. Downstream layers will not see the mask.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_9\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional_9\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)        </span>┃<span style=\"font-weight: bold\"> Output Shape      </span>┃<span style=\"font-weight: bold\">    Param # </span>┃<span style=\"font-weight: bold\"> Connected to      </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">22</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ input_layer_1       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">22</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ encoder (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Encoder</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">22</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)   │  <span style=\"color: #00af00; text-decoration-color: #00af00\">2,648,576</span> │ input_layer[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ decoder (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Decoder</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">22</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)   │  <span style=\"color: #00af00; text-decoration-color: #00af00\">4,758,784</span> │ input_layer_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "│                     │                   │            │ encoder[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_16 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">22</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">70</span>)    │      <span style=\"color: #00af00; text-decoration-color: #00af00\">9,030</span> │ decoder[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m22\u001b[0m)        │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ input_layer_1       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m22\u001b[0m)        │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ encoder (\u001b[38;5;33mEncoder\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m22\u001b[0m, \u001b[38;5;34m128\u001b[0m)   │  \u001b[38;5;34m2,648,576\u001b[0m │ input_layer[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ decoder (\u001b[38;5;33mDecoder\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m22\u001b[0m, \u001b[38;5;34m128\u001b[0m)   │  \u001b[38;5;34m4,758,784\u001b[0m │ input_layer_1[\u001b[38;5;34m0\u001b[0m]… │\n",
       "│                     │                   │            │ encoder[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_16 (\u001b[38;5;33mDense\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m22\u001b[0m, \u001b[38;5;34m70\u001b[0m)    │      \u001b[38;5;34m9,030\u001b[0m │ decoder[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">7,416,390</span> (28.29 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m7,416,390\u001b[0m (28.29 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">7,416,390</span> (28.29 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m7,416,390\u001b[0m (28.29 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "transformer = Transformer(\n",
    "    num_layers=configs.num_layers,\n",
    "    d_model=configs.d_model,\n",
    "    num_heads=configs.num_heads,\n",
    "    dff=configs.dff,\n",
    "    input_vocab_size=len(tokenizer)+1,\n",
    "    target_vocab_size=len(detokenizer)+1,\n",
    "    dropout_rate=configs.dropout_rate,\n",
    "    encoder_input_size=tokenizer.max_length,\n",
    "    decoder_input_size=detokenizer.max_length\n",
    "    )\n",
    "\n",
    "transformer.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from CustomSchedule import CustomSchedule\n",
    "\n",
    "learning_rate = CustomSchedule(configs.d_model)\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate, beta_1=0.9, beta_2=0.98,\n",
    "                                     epsilon=1e-9)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mltu.tensorflow.transformer.utils import MaskedLoss\n",
    "from mltu.tensorflow.transformer.utils import MaskedAccuracy\n",
    "\n",
    "transformer.compile(\n",
    "    loss=MaskedLoss(),\n",
    "    optimizer=optimizer,\n",
    "    metrics=[MaskedAccuracy()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/thanhan/.local/lib/python3.10/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:120: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 465ms/step - loss: 4.8340 - masked_accuracy: 0.0177 - val_loss: 4.6506 - val_masked_accuracy: 0.0438\n",
      "Epoch 2/20\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 255ms/step - loss: 4.6561 - masked_accuracy: 0.0121 - val_loss: 4.7772 - val_masked_accuracy: 0.0637\n",
      "Epoch 3/20\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 234ms/step - loss: 4.4998 - masked_accuracy: 0.0369 - val_loss: 4.1421 - val_masked_accuracy: 0.0677\n",
      "Epoch 4/20\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 253ms/step - loss: 4.2515 - masked_accuracy: 0.0412 - val_loss: 3.9337 - val_masked_accuracy: 0.0797\n",
      "Epoch 5/20\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 238ms/step - loss: 3.9753 - masked_accuracy: 0.0663 - val_loss: 3.8098 - val_masked_accuracy: 0.0757\n",
      "Epoch 6/20\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 243ms/step - loss: 3.7387 - masked_accuracy: 0.0959 - val_loss: 3.8551 - val_masked_accuracy: 0.0876\n",
      "Epoch 7/20\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 225ms/step - loss: 3.5681 - masked_accuracy: 0.1190 - val_loss: 3.3531 - val_masked_accuracy: 0.1116\n",
      "Epoch 8/20\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 270ms/step - loss: 3.4417 - masked_accuracy: 0.1516 - val_loss: 3.4581 - val_masked_accuracy: 0.1076\n",
      "Epoch 9/20\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 252ms/step - loss: 3.3475 - masked_accuracy: 0.1560 - val_loss: 3.3929 - val_masked_accuracy: 0.1315\n",
      "Epoch 10/20\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 262ms/step - loss: 3.3304 - masked_accuracy: 0.1481 - val_loss: 3.5068 - val_masked_accuracy: 0.1355\n",
      "Epoch 11/20\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 238ms/step - loss: 3.2235 - masked_accuracy: 0.1786 - val_loss: 3.4037 - val_masked_accuracy: 0.1355\n",
      "Epoch 12/20\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 244ms/step - loss: 3.1798 - masked_accuracy: 0.1906 - val_loss: 3.5262 - val_masked_accuracy: 0.1394\n",
      "Epoch 13/20\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 226ms/step - loss: 3.1617 - masked_accuracy: 0.1861 - val_loss: 3.3669 - val_masked_accuracy: 0.1434\n",
      "Epoch 14/20\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 237ms/step - loss: 3.0412 - masked_accuracy: 0.2082 - val_loss: 3.2038 - val_masked_accuracy: 0.1633\n",
      "Epoch 15/20\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 248ms/step - loss: 3.0264 - masked_accuracy: 0.2216 - val_loss: 3.0717 - val_masked_accuracy: 0.1673\n",
      "Epoch 16/20\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 226ms/step - loss: 2.9579 - masked_accuracy: 0.2286 - val_loss: 3.1766 - val_masked_accuracy: 0.2032\n",
      "Epoch 17/20\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 215ms/step - loss: 2.9236 - masked_accuracy: 0.2417 - val_loss: 3.3121 - val_masked_accuracy: 0.1952\n",
      "Epoch 18/20\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 221ms/step - loss: 2.8333 - masked_accuracy: 0.2575 - val_loss: 3.0962 - val_masked_accuracy: 0.2191\n",
      "Epoch 19/20\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 222ms/step - loss: 2.8193 - masked_accuracy: 0.2623 - val_loss: 2.9842 - val_masked_accuracy: 0.2231\n",
      "Epoch 20/20\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 221ms/step - loss: 2.7014 - masked_accuracy: 0.2846 - val_loss: 2.9707 - val_masked_accuracy: 0.2311\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x7c5845485480>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transformer.fit(\n",
    "    train_dataProvider,\n",
    "    epochs=configs.train_epochs,\n",
    "    validation_data=val_dataProvider\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['el mal.', 'y luego ...', '¡no!', 'mira esto.', 'protestas en daca.', 'alguien me la jugó', 'ya...', '¿puedo fumar uno?', '- tres millones.', '[risa]', 'son los negocios.', 'espérenme.', 'puedo esperar.', '¡seif!', '¿ah, sí?', 'soy yo.']\n",
      "['<start>evil.', '<start>and then...', '<start>no!', '<start>look at this.', '<start>protests in dhaka.', '<start>someone betrayed me.', '<start>i...', '<start>can i have one?', '<start>three million.', '<start>[laughter]', \"<start>it's business.\", '<start>wait for me.', '<start>i can wait.', '<start>prepare yourself!', '<start>oh, yeah?', \"<start>it's me.\"]\n",
      "['evil.<eos>', 'and then...<eos>', 'no!<eos>', 'look at this.<eos>', 'protests in dhaka.<eos>', 'someone betrayed me.<eos>', 'i...<eos>', 'can i have one?<eos>', 'three million.<eos>', '[laughter]<eos>', \"it's business.<eos>\", 'wait for me.<eos>', 'i can wait.<eos>', 'prepare yourself!<eos>', 'oh, yeah?<eos>', \"it's me.<eos>\"]\n"
     ]
    }
   ],
   "source": [
    "for data_batch in train_dataProvider:\n",
    "    (encoder_inputs, decoder_inputs), decoder_outputs = data_batch\n",
    "\n",
    "    encoder_inputs_str = tokenizer.detokenize(encoder_inputs)\n",
    "    decoder_inputs_str = detokenizer.detokenize(decoder_inputs, remove_start_end=False)\n",
    "    decoder_outputs_str = detokenizer.detokenize(decoder_outputs, remove_start_end=False)\n",
    "    print(encoder_inputs_str)\n",
    "    print(decoder_inputs_str)\n",
    "    print(decoder_outputs_str)\n",
    "    \n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'shape'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[21], line 5\u001b[0m\n\u001b[1;32m      2\u001b[0m sequences \u001b[38;5;241m=\u001b[39m tokenizer\u001b[38;5;241m.\u001b[39mtexts_to_sequences([sentence])\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# print(sequences)\u001b[39;00m\n\u001b[0;32m----> 5\u001b[0m \u001b[43mtransformer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43marray\u001b[49m\u001b[43m(\u001b[49m\u001b[43msequences\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py:122\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m    120\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m    121\u001b[0m     \u001b[38;5;66;03m# `keras.config.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m--> 122\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    123\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    124\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/keras/src/trainers/data_adapters/data_adapter_utils.py:103\u001b[0m, in \u001b[0;36m<genexpr>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    102\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcheck_data_cardinality\u001b[39m(data):\n\u001b[0;32m--> 103\u001b[0m     num_samples \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m(\u001b[38;5;28mint\u001b[39m(\u001b[43mi\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m[\u001b[38;5;241m0\u001b[39m]) \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m tree\u001b[38;5;241m.\u001b[39mflatten(data))\n\u001b[1;32m    104\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(num_samples) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m    105\u001b[0m         msg \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    106\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mData cardinality is ambiguous. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    107\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMake sure all arrays contain the same number of samples.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    108\u001b[0m         )\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'shape'"
     ]
    }
   ],
   "source": [
    "sentence = 'el mal.'\n",
    "sequences = tokenizer.texts_to_sequences([sentence])\n",
    "\n",
    "# print(sequences)\n",
    "transformer.predict([None, np.array(sequences)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'MAX_TOKENS' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m \u001b[38;5;21;01mTranslator\u001b[39;00m(tf\u001b[38;5;241m.\u001b[39mModule):\n\u001b[1;32m      2\u001b[0m   \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, tokenizers, transformer):\n\u001b[1;32m      3\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtokenizers \u001b[38;5;241m=\u001b[39m tokenizers\n",
      "Cell \u001b[0;32mIn[14], line 6\u001b[0m, in \u001b[0;36mTranslator\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtokenizers \u001b[38;5;241m=\u001b[39m tokenizers\n\u001b[1;32m      4\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransformer \u001b[38;5;241m=\u001b[39m transformer\n\u001b[0;32m----> 6\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, sentence, max_length\u001b[38;5;241m=\u001b[39m\u001b[43mMAX_TOKENS\u001b[49m):\n\u001b[1;32m      7\u001b[0m   \u001b[38;5;66;03m# The input sentence is Portuguese, hence adding the `[START]` and `[END]` tokens.\u001b[39;00m\n\u001b[1;32m      8\u001b[0m   \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(sentence, tf\u001b[38;5;241m.\u001b[39mTensor)\n\u001b[1;32m      9\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(sentence\u001b[38;5;241m.\u001b[39mshape) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "\u001b[0;31mNameError\u001b[0m: name 'MAX_TOKENS' is not defined"
     ]
    }
   ],
   "source": [
    "class Translator(tf.Module):\n",
    "  def __init__(self, tokenizers, transformer):\n",
    "    self.tokenizers = tokenizers\n",
    "    self.transformer = transformer\n",
    "\n",
    "  def __call__(self, sentence, max_length=20):\n",
    "    # The input sentence is Portuguese, hence adding the `[START]` and `[END]` tokens.\n",
    "    assert isinstance(sentence, tf.Tensor)\n",
    "    if len(sentence.shape) == 0:\n",
    "      sentence = sentence[tf.newaxis]\n",
    "\n",
    "    sentence = self.tokenizers.pt.tokenize(sentence).to_tensor()\n",
    "\n",
    "    encoder_input = sentence\n",
    "\n",
    "    # As the output language is English, initialize the output with the\n",
    "    # English `[START]` token.\n",
    "    start_end = self.tokenizers.en.tokenize([''])[0]\n",
    "    start = start_end[0][tf.newaxis]\n",
    "    end = start_end[1][tf.newaxis]\n",
    "\n",
    "    # `tf.TensorArray` is required here (instead of a Python list), so that the\n",
    "    # dynamic-loop can be traced by `tf.function`.\n",
    "    output_array = tf.TensorArray(dtype=tf.int64, size=0, dynamic_size=True)\n",
    "    output_array = output_array.write(0, start)\n",
    "\n",
    "    for i in tf.range(max_length):\n",
    "      output = tf.transpose(output_array.stack())\n",
    "      predictions = self.transformer([encoder_input, output], training=False)\n",
    "\n",
    "      # Select the last token from the `seq_len` dimension.\n",
    "      predictions = predictions[:, -1:, :]  # Shape `(batch_size, 1, vocab_size)`.\n",
    "\n",
    "      predicted_id = tf.argmax(predictions, axis=-1)\n",
    "\n",
    "      # Concatenate the `predicted_id` to the output which is given to the\n",
    "      # decoder as its input.\n",
    "      output_array = output_array.write(i+1, predicted_id[0])\n",
    "\n",
    "      if predicted_id == end:\n",
    "        break\n",
    "\n",
    "    output = tf.transpose(output_array.stack())\n",
    "    # The output shape is `(1, tokens)`.\n",
    "    text = tokenizers.en.detokenize(output)[0]  # Shape: `()`.\n",
    "\n",
    "    tokens = tokenizers.en.lookup(output)[0]\n",
    "\n",
    "    # `tf.function` prevents us from using the attention_weights that were\n",
    "    # calculated on the last iteration of the loop.\n",
    "    # So, recalculate them outside the loop.\n",
    "    self.transformer([encoder_input, output[:,:-1]], training=False)\n",
    "    attention_weights = self.transformer.decoder.last_attn_scores\n",
    "\n",
    "    return text, tokens, attention_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sí, Joe.\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'shape'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[15], line 13\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m es, en \u001b[38;5;129;01min\u001b[39;00m val_examples:\n\u001b[1;32m     12\u001b[0m     \u001b[38;5;28mprint\u001b[39m(es)\n\u001b[0;32m---> 13\u001b[0m     results, duration \u001b[38;5;241m=\u001b[39m \u001b[43mtranslator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mes\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     14\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSpanish:     \u001b[39m\u001b[38;5;124m\"\u001b[39m, es\u001b[38;5;241m.\u001b[39mlower())\n\u001b[1;32m     15\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEnglish:     \u001b[39m\u001b[38;5;124m\"\u001b[39m, en\u001b[38;5;241m.\u001b[39mlower())\n",
      "File \u001b[0;32m~/Documents/projects/python/spell-checker/src/Translator.py:22\u001b[0m, in \u001b[0;36mTranslator.predict\u001b[0;34m(self, sentence)\u001b[0m\n\u001b[1;32m     17\u001b[0m decoder_input \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mpad(tokenized_results, (\u001b[38;5;241m0\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdetokenizer\u001b[38;5;241m.\u001b[39mmax_length \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mlen\u001b[39m(tokenized_results)), constant_values\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\u001b[38;5;241m.\u001b[39mastype(np\u001b[38;5;241m.\u001b[39mint64)\n\u001b[1;32m     18\u001b[0m input_dict \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m     19\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39mname: np\u001b[38;5;241m.\u001b[39mexpand_dims(encoder_input, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m),\n\u001b[1;32m     20\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39mname: np\u001b[38;5;241m.\u001b[39mexpand_dims(decoder_input, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m),\n\u001b[1;32m     21\u001b[0m }\n\u001b[0;32m---> 22\u001b[0m preds \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_dict\u001b[49m\u001b[43m)\u001b[49m[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;66;03m# preds shape (1, 206, 29110)\u001b[39;00m\n\u001b[1;32m     23\u001b[0m pred_results \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39margmax(preds, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)\n\u001b[1;32m     24\u001b[0m tokenized_results\u001b[38;5;241m.\u001b[39mappend(pred_results[\u001b[38;5;241m0\u001b[39m][index])\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py:122\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m    120\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m    121\u001b[0m     \u001b[38;5;66;03m# `keras.config.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m--> 122\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    123\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    124\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/keras/src/trainers/data_adapters/data_adapter_utils.py:103\u001b[0m, in \u001b[0;36m<genexpr>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    102\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcheck_data_cardinality\u001b[39m(data):\n\u001b[0;32m--> 103\u001b[0m     num_samples \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m(\u001b[38;5;28mint\u001b[39m(\u001b[43mi\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m[\u001b[38;5;241m0\u001b[39m]) \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m tree\u001b[38;5;241m.\u001b[39mflatten(data))\n\u001b[1;32m    104\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(num_samples) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m    105\u001b[0m         msg \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    106\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mData cardinality is ambiguous. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    107\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMake sure all arrays contain the same number of samples.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    108\u001b[0m         )\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'shape'"
     ]
    }
   ],
   "source": [
    "translator = Translator(\n",
    "    transformer=transformer, tokenizer=tokenizer, detokenizer=detokenizer\n",
    ")\n",
    "\n",
    "val_examples = [\n",
    "    [es_sentence, en_sentence]\n",
    "    for es_sentence, en_sentence in zip(es_val_data, en_val_data)\n",
    "    if len(es_sentence) <= max_length and len(en_sentence) <= max_length\n",
    "]\n",
    "val_dataset = []\n",
    "for es, en in val_examples:\n",
    "    print(es)\n",
    "    results, duration = translator.predict(es)\n",
    "    print(\"Spanish:     \", es.lower())\n",
    "    print(\"English:     \", en.lower())\n",
    "    print(\"English pred:\", results)\n",
    "    print(duration)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
