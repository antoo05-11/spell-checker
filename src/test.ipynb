{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from positional_embedding import positional_encoding\n",
    "\n",
    "pos_encoding = positional_encoding(length=2048, depth=512)\n",
    "\n",
    "# Check the shape.\n",
    "print(pos_encoding.shape)\n",
    "\n",
    "# Plot the dimensions.\n",
    "plt.pcolormesh(pos_encoding.numpy().T, cmap=\"RdBu\")\n",
    "plt.ylabel(\"Depth\")\n",
    "plt.xlabel(\"Position\")\n",
    "plt.colorbar()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "pos_encoding /= tf.norm(pos_encoding, axis=1, keepdims=True)\n",
    "p = pos_encoding[1000]\n",
    "dots = tf.einsum(\"pd,d->p\", pos_encoding, p).numpy()\n",
    "\n",
    "plt.subplot(2, 1, 1)\n",
    "plt.plot(dots)\n",
    "plt.ylim([0, 1])\n",
    "plt.plot(\n",
    "    [950, 950, float(\"nan\"), 1050, 1050],\n",
    "    [0, 1, float(\"nan\"), 0, 1],\n",
    "    color=\"k\",\n",
    "    label=\"Zoom\",\n",
    ")\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(2, 1, 2)\n",
    "plt.plot(range(len(dots)), dots)\n",
    "plt.xlim([950, 1050])\n",
    "plt.ylim([0, 1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from positional_embedding import PositionalEmbedding\n",
    "\n",
    "vocab_size = 1000\n",
    "d_model = 512\n",
    "\n",
    "embedding_layer = PositionalEmbedding(vocab_size, d_model)\n",
    "\n",
    "random_input = np.random.randint(0, vocab_size, size=(1, 100))\n",
    "\n",
    "output = embedding_layer(random_input)\n",
    "print(\"random_input shape\", random_input.shape)\n",
    "print(\"PositionalEmbedding output\", output.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from positional_embedding import PositionalEmbedding\n",
    "from cross_attention import CrossAttention\n",
    "import numpy as np\n",
    "\n",
    "vocab_size = 1000\n",
    "encoder_vocab_size = 1000\n",
    "decoder_vocab_size = 1100\n",
    "d_model = 512\n",
    "\n",
    "encoder_embedding_layer = PositionalEmbedding(vocab_size, d_model)\n",
    "decoder_embedding_layer = PositionalEmbedding(vocab_size, d_model)\n",
    "\n",
    "random_encoder_input = np.random.randint(0, encoder_vocab_size, size=(1, 100))\n",
    "random_decoder_input = np.random.randint(0, decoder_vocab_size, size=(1, 110))\n",
    "\n",
    "encoder_embeddings = encoder_embedding_layer(random_encoder_input)\n",
    "decoder_embeddings = decoder_embedding_layer(random_decoder_input)\n",
    "\n",
    "print(\"encoder_embeddings shape\", encoder_embeddings.shape)\n",
    "print(\"decoder_embeddings shape\", decoder_embeddings.shape)\n",
    "\n",
    "cross_attention_layer = CrossAttention(num_heads=2, key_dim=512)\n",
    "cross_attention_output = cross_attention_layer(decoder_embeddings, encoder_embeddings)\n",
    "\n",
    "print(\"cross_attention_output shape\", cross_attention_output.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from positional_embedding import PositionalEmbedding\n",
    "from casual_self_attention import CausalSelfAttention\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "vocab_size = 1000\n",
    "decoder_vocab_size = 1100\n",
    "d_model = 512\n",
    "\n",
    "decoder_embedding_layer = PositionalEmbedding(vocab_size, d_model)\n",
    "\n",
    "random_decoder_input = np.random.randint(0, decoder_vocab_size, size=(1, 110))\n",
    "\n",
    "decoder_embeddings = decoder_embedding_layer(random_decoder_input)\n",
    "\n",
    "print(\"decoder_embeddings shape\", decoder_embeddings.shape)\n",
    "\n",
    "causal_self_attention_layer = CausalSelfAttention(num_heads=2, key_dim=512)\n",
    "causal_self_attention_output = causal_self_attention_layer(decoder_embeddings)\n",
    "\n",
    "print(\"causal_self_attention_output shape\", causal_self_attention_output.shape)\n",
    "\n",
    "out1 = causal_self_attention_layer(decoder_embedding_layer(random_decoder_input[:, :50])) # Only the first 50 tokens beffore applying the embedding layer\n",
    "out2 = causal_self_attention_layer(decoder_embedding_layer(random_decoder_input)[:, :50]) # Only the first 50 tokens after applying the embedding layer\n",
    "\n",
    "diff = tf.reduce_max(tf.abs(out1 - out2)).numpy()\n",
    "\n",
    "print(\"Difference between the two outputs:\", diff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from positional_embedding import PositionalEmbedding\n",
    "from global_self_attention import GlobalSelfAttention\n",
    "\n",
    "vocab_size = 1000\n",
    "encoder_vocab_size = 1000\n",
    "d_model = 512\n",
    "\n",
    "encoder_embedding_layer = PositionalEmbedding(vocab_size, d_model)\n",
    "\n",
    "random_encoder_input = np.random.randint(0, encoder_vocab_size, size=(1, 100))\n",
    "\n",
    "encoder_embeddings = encoder_embedding_layer(random_encoder_input)\n",
    "\n",
    "print(\"encoder_embeddings shape\", encoder_embeddings.shape)\n",
    "\n",
    "cross_attention_layer = GlobalSelfAttention(num_heads=2, key_dim=512)\n",
    "cross_attention_output = cross_attention_layer(encoder_embeddings)\n",
    "\n",
    "print(\"global_self_attention_output shape\", cross_attention_output.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from positional_embedding import PositionalEmbedding\n",
    "import numpy as np\n",
    "from feed_forward_layer import FeedForward\n",
    "\n",
    "encoder_vocab_size = 1000\n",
    "vocab_size = 1000\n",
    "d_model = 512\n",
    "\n",
    "encoder_embedding_layer = PositionalEmbedding(vocab_size, d_model)\n",
    "\n",
    "random_encoder_input = np.random.randint(0, encoder_vocab_size, size=(1, 100))\n",
    "\n",
    "encoder_embeddings = encoder_embedding_layer(random_encoder_input)\n",
    "\n",
    "print(\"encoder_embeddings shape\", encoder_embeddings.shape)\n",
    "\n",
    "feed_forward_layer = FeedForward(d_model, dff=2048)\n",
    "feed_forward_output = feed_forward_layer(encoder_embeddings)\n",
    "\n",
    "print(\"feed_forward_output shape\", feed_forward_output.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from encoder import EncoderLayer\n",
    "\n",
    "encoder_vocab_size = 1000\n",
    "d_model = 512\n",
    "\n",
    "encoder_embedding_layer = PositionalEmbedding(vocab_size, d_model)\n",
    "\n",
    "random_encoder_input = np.random.randint(0, encoder_vocab_size, size=(1, 100))\n",
    "\n",
    "encoder_embeddings = encoder_embedding_layer(random_encoder_input)\n",
    "\n",
    "print(\"encoder_embeddings shape\", encoder_embeddings.shape)\n",
    "\n",
    "encoder_layer = EncoderLayer(d_model, num_heads=2, dff=2048)\n",
    "\n",
    "encoder_layer_output = encoder_layer(encoder_embeddings)\n",
    "\n",
    "print(\"encoder_layer_output shape\", encoder_layer_output.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test encoder layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from encoder import Encoder\n",
    "\n",
    "encoder_vocab_size = 1000\n",
    "d_model = 512\n",
    "\n",
    "encoder = Encoder(num_layers=2, d_model=d_model, num_heads=2, dff=2048, vocab_size=encoder_vocab_size)\n",
    "\n",
    "random_encoder_input = np.random.randint(0, encoder_vocab_size, size=(1, 100))\n",
    "\n",
    "encoder_output = encoder(random_encoder_input)\n",
    "\n",
    "print(\"random_encoder_input shape\", random_encoder_input.shape)\n",
    "print(\"encoder_output shape\", encoder_output.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test Decoder Layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from decoder import DecoderLayer\n",
    "\n",
    "decoder_vocab_size = 1000\n",
    "d_model = 512\n",
    "dff = 2048\n",
    "num_heads = 8\n",
    "\n",
    "decoder_layer = DecoderLayer(d_model, num_heads, dff)\n",
    "\n",
    "random_decoderLayer_input = np.random.randint(0, decoder_vocab_size, size=(1, 110))\n",
    "\n",
    "decoder_embeddings = encoder_embedding_layer(random_decoderLayer_input)\n",
    "\n",
    "decoderLayer_output = decoder_layer(decoder_embeddings, encoder_output)\n",
    "\n",
    "print(\"random_decoder_input shape\", random_decoderLayer_input.shape)\n",
    "print(\"decoder_embeddings shape\", decoder_embeddings.shape)\n",
    "print(\"decoder_output shape\", decoderLayer_output.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from decoder import Decoder\n",
    "\n",
    "decoder_vocab_size = 1000\n",
    "d_model = 512\n",
    "\n",
    "decoder_layer = Decoder(num_layers=2, d_model=d_model, num_heads=2, dff=2048, vocab_size=decoder_vocab_size)\n",
    "\n",
    "random_decoder_input = np.random.randint(0, decoder_vocab_size, size=(1, 100))\n",
    "\n",
    "decoder_output = decoder_layer(random_decoder_input, encoder_output)\n",
    "\n",
    "print(\"random_decoder_input shape\", random_decoder_input.shape)\n",
    "print(\"decoder_output shape\", decoder_output.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tranformer import Transformer\n",
    "\n",
    "encoder_input_size = 100\n",
    "decoder_input_size = 110\n",
    "\n",
    "encoder_vocab_size = 1000\n",
    "decoder_vocab_size = 1000\n",
    "\n",
    "model = Transformer(\n",
    "    input_vocab_size=encoder_vocab_size,\n",
    "    target_vocab_size=decoder_vocab_size,\n",
    "    encoder_input_size=encoder_input_size,\n",
    "    decoder_input_size=decoder_input_size,\n",
    "    num_layers=2,\n",
    "    d_model=512,\n",
    "    num_heads=2,\n",
    "    dff=512,\n",
    "    dropout_rate=0.1)\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
